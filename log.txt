log:

* Implemented noun morphology following HJK
   - worst case constructor 6 forms
   - Finnish worst case constructor 10 forms
* Verb morphology
   - Regular internal representation 4 forms
   - 25 irregular verbs that need 8 forms
   - 2 irregular verbs defined separately
   - Finnish worst case constructor 12 forms
   
Other changes
   - Removed question particles from the category of verbs
   - Removed possessive suffix from nouns and dets
   - Removed vowel harmony features
   - Added "oma" possessive to Extra
   - Removed CompPartAP from Extra: copula complement is in nominative    CompPartAP : AP -> Comp ; -- kahvi on valmista
   - To remove from Extra:
    	- Particles (-han, -pa etc.)
    	- Word orders with focused member
   	- PartCN?
   	- 
   - To add:
   	- püsiühendid
        - negation "pole" to Extra


Inari 29.8.2013

TS classification are not always very logical. For instance, 49 is one class which I split in three 1-argument functions: saama~saada ; jooma~juua ; käima~käia. (I could of course just do more matching inside the ``Str -> VForms`` function. Maybe this detail is not so important anyway.)
Classes 50-52 are identical. Stem that you get from ma infinitive doesn't change, you just add suffixes.
Classes 55-57 are identical, just the details of consonant gradation differ. 55 is pp~p, 56 is nd~nn, 57 is lugema~loeb or pidama~peab. 
Class 61 contains both a and e (laulab, kooleb), and you don't know that from ma infinitive.
I merged 62 and 64, because the only difference is that other has consonant gradation and other doesn't. So you can give instruction ``X_weak + "suffix"``, and if X can't be made weaker, it has no effect.

Inari 1.9.2013

Paradigm from a CS point of view and a linguistic point of view; 
definition of (Aarne & Gregoire smart paradigms paper http://www.aclweb.org/anthology/E/E12/E12-1066.pdf); paradigm is a function that you apply to one form to give you n forms, that is, the full inflection table of a lemma. If you consider it as an instruction, 62 and 64 are in the same class: applying the same procedure gives the full inflection table for all words that belong to the TS classes 62 and 64. 
If you consider it as a description, it is more justified to separate the classes. One contains consonant gradation, other doesn't.
Difference between classes 51 and 55-57 is that 51 does not undergo consonant gradation, 55-57 do. They aren't implemented in the same smart paradigm, because verbs 51 could potentially undergo it; that is, applying function ``weaker`` to stems of 51 verbs would transform them and that would result in incorrect forms.

With nouns, we use the HJK (http://kjk.eki.ee/ee/issues/2012/6/156) system, where the full inflection table of a noun can be formed by 6 forms. What is then left to do for the GF smart paradigms is how to form the 6 forms from one.
With verbs the number of forms for forming the full paradigm is 8 -- this is enough for all verbs except _olema_ and _minema_, which are just formed separately. With the assumption that 6 and 8 forms are enough to compute all other forms, we have reduced the immediate problem to finding 6/8 forms based on one.

An example of the template for verbs in TS 63.
The suffixes are fixed; you couldn't produce for instance any verb that has the vowel _e_ in the present tense personal forms, or imperative with the allomorph _ge_.
Second thing is that you can't form a verb whose stem behaves differently. For instance, the verbs _õppima_ and _hüppama_ have different quantities in present tense forms (_õpib_ and _hüppab_), so you can't describe the process that happens in the stem in the same function. 
These are both very intuitive definitions; behaviour and instructions coincide.

  -- TS 63 (andma, murdma, hoidma) 
  cAndma : Str -> VForms = \andma ->
    let
      and = tk 2 andma ;   --murd(ma), hoid(ma)
      an = tk 1 and ;      --mur(d),   hoi(d)
      ann = weaker and ;   --murr,     hoi
    in vForms8
      andma
      (and + "a")
      (ann + "ab")
      (an + "takse")
      (and + "ke")
      (and + "is")
      (and + "nud")
      (an + "tud") ;

Kaarel 5.9.2013

Tested the 1-arg noun paradigm.

  1. Took all nouns from the Estonian WordNet: 65214
  2. Applied Filosoft compound splitting to them
  3. Removed 24262 nouns for which compound splitting failed (Filosoft tag ####)
     TODO: investigate why is this number so large
  4. For the remaining words, removed everything up to the last compound part.
     After sort|uniq, this resulted in 17983 words (non-compounds are also included)
  5. Applied Filosoft morph. generation
  6. Removed words for which generation failed (Filosoft tag ####), resulting in 17551 words
  7. Applied "recode latin1..utf8" which fixed 3 encoding errors that crashed (?) GF (TODO: report this to Filosoft)
     hea, hea, head, heasse, heade, häid
     make-up, make-upi, make-upi, make-upisse|make-upi, make-upide, make-upu|make-upisid
     pea, pea, pead, peasse|pähe, peade, päid
  8. Ran GF's cc on the sg nom forms, something like:

     cat nouns.6forms.csv | sed "s/,.*//" | ./cc.py -r HjkEst.gf --oper "hjk_type" |\
     gf --run | perl -nal -F",\s+" -e 'print "$F[0], $F[1], $F[2], $F[3], $F[15], $F[16]"'

  9. Compared the output against the Filosoft original file using diff-list-set.py,
     resulting in this difference distribution (e.g. 5-6 means that only the plural forms are wrong)

      13853
       1507 2-3-4-5-6
        524 3-5-6
        425 3-4-5-6
        267 2-3-4-5
        251 5-6
        219 2
        186 6
        112 2-4-6
         58 3
         55 2-4-5-6
         50 2-3-5-6
         32 2-4
          9 3-5
          1 4-6
          1 2-3-4-6
          1 2-3-4

So, about 79% of the nouns are currently handled correctly.

Inari 5.9.

1) Added particle verbs. Added a s2 field for Verb, and used the pre-existing ext field in VP for the particle.

Clauses with verb complement require an inverted word order. Modified the function infVP (ResEst) to handle that. ComplVV calls infVP, which inverts the word order for the complement VP, and puts it into the resulting VP's complement field. This happens to all cases with auxiliary, but not with negation:

  * mina saan sinust aru
  * mina ei saa sinust aru
  * mina tahan sinust aru saada
  
Added also a third SType, SInv, for forming inverted word order in mkClause (ResEst).
SInv made by mkClause may be needed for cases where you just need to construct an inverted word order, for whichever pragmatic reason, and then call it from some other place, e.g. application grammar or ExtraEst function.

2) Started testing the syntax. Copied exx-resource.gfs from GF main repo, testsuite/libraries. Now exx-resource.gfs.gold is just the output, TODO correct that and diff after changing something.

Inari 8.9.

Tested the 1-arg verb paradigm.

  1. Took (all?) verbs from the Estonian WordNet: 7845
  2. Excluded 587 verbs for which generation failed (Filosoft tag ####)
  3. Excluded 1282 compound verbs (e.g. 'kinni hoidma'), resulting in 5976 words 
  4. Ran GF's cc on the ma forms, same procedure as for nouns:
       
       cat verbs.8forms.csv | sed "s/,.*//" |\
       python cc.py -r /ParadigmsEst.gf --oper "mkV" |\
       gf --run |\
       perl -nal -F",\s+" -e 'print "$F[2], $F[0], $F[9], $F[31], $F[26], $F[15], $F[36], $F[65]"'

  5. Compared the output against the Filosoft original file using diff-list-set.py, resulting in this difference distribution (e.g. 4-8 means that passive present and passive participle are wrong.)

forms:  1 = ma   2 = da   3 = b   4 = takse
        5 = ge   6 = s    7 = nud   8 = tud         

   5262
    240 3-4-8
    198 7
    101 2-5
     90 2-4-5-7-8
     47 2-4-5-8
      9 3
      8 4-8
      7 6
      6 2-4-6-8
      3 2-3-4-5-6-7-8
      2 2-4-8
      2 2-3-4-6-8
      1 4-6-8
      1 2-4-6
      
88 % of the verbs get correct result from 1-arg smart paradigm.

Inari 9.9.
----------

Fixed consonant gradation patterns; only frequent and stable in weaker, irregular patterns in MorphoEst opers.
      
   5567
    139 3-4-8
    130 2-4-5-7-8
     99 2-5
     11 3
     10 4-8
      7 6
      6 2-4-6-8
      2 2-4-8
      2 2-3-4-6-8
      2 2-3-4-5-6-7-8
      1 4-6-8
      1 2-4-6


Kaarel 10.09
------------

Tested adjectives in the same way as nouns but without compound splitting.
Improved the handling of -ne words (40% of the adjectives).

Adjectives:

   4272
    418 2-3-4-5-6
    368 3-5-6
    138 6
     60 2-4-6
     19 2-4-5-6
     14 5-6
     10 2-3-4-5
      5 3-5
      1 3
      1 2
Coverage: 4272 out of 5306 = .8051

Nouns:

  15681
    605 2-3-4-5-6
    258 2-3-4-5
    201 5-6
    128 3-5-6
     90 2-4-6
     85 6
     51 2-4-5-6
     33 3-4-5-6
     31 2-4
     28 3
     13 2
      3 3-5
      1 5
      1 4-6
      1 2-3-4
Coverage: 15681 out of 17210 = .9111


Kaarel 10.09
------------

Tested on a larger set of nouns (+4500). Previous set excluded õäöüšž-nouns
because forgot to use the "-cio utf8" flag. Somehow didn't notice this before...

  19695
    816 2-3-4-5-6
    357 2-3-4-5
    257 5-6
    168 3-5-6
    135 2-4-6
    118 6
     89 2-4-5-6
     40 3-4-5-6
     36 3
     36 2-4
     19 2
      5 3-5
      3 2-3-4
      1 5
      1 4-6
Coverage: 19695 out of 21776 = .9044


Inari 13.9.
-----------

Testing [1-4]-arg mkVs

1-arg:
   5411
    201 2-4-5-7-8
    200 2-5
    134 3-4-8
      9 4-8
      7 3
      5 6
      2 2-4
      2 2-3-4-6-8
      2 2-3-4-5-6-7-8
      1 2-4-8
      1 2-4-6-8
      1 2-4-5-6-7-8      
Coverage: 5411 out of 5976 = .9054

2-arg:
   5770
    134 3-4-8
     40 2-4-5-7-8
      9 4-8
      6 3
      5 6
      3 2-3-4-6-8
      2 2-4
      2 2-3-4-5-8
      1 3-6-7
      1 2-4-8
      1 2-4-6-8      
Coverage: 5770 out of 5976 = .9655

3-arg:
   5873
     40 2-4-5-7-8
     17 2-4-8
     10 4-8
      8 2-4-5-6-8
      6 2-4-6-8
      5 3-4-8
      4 2-4-5-6-7-8
      2 6
      2 4-6-8
      2 4-5-8
      2 3
      2 2-4-5-8
      2 2-3-4-6-8
      1 3-6-7      
Coverage: 5873 out of 5976 = .9827

4-arg:
   5960
      6 5-6-7-8
      4 6
      4 5-7-8
      1 3-6-7
      1 3
Coverage: 5960 out of 5976 = .9973

16 verbs out of 5976 need a 8-arg constructor.

EKK09 says that all except the named 27 verbs can be formed from 4 forms; ma, da, b, takse (http://www.eki.ee/books/ekk09/index.php?p=3&p1=5&id=227).

1. Possibe counterexamples? 

a) Forming the imperfect forms from ma stem 

  jooksma : 62
  jooks/ma, joos/ta, jooks/eb, joos/takse
	Impf Sg P3 => jooks/is

  maitsma : 62
  maits/ma, maits/ta, maits/eb, maits/takse
	Impf Sg P3 => maits/es
	
The choice of vowel (e/i) is not obvious from any of the 4 forms.
	
b) Forming the past participle (nud) from da
  
  jooksma : 62
  jooks/ma, joos/ta, jooks/eb, joos/takse
	PastPartAct Sg Nom => joos/nud 
	
  laskma : 64
  lask/ma, las/ta, las/eb, las/takse
	PastPartAct Sg Nom => lask/nud 

Verbs that end in -kma, actually the past participle is formed with ma stem, not da stem.	
  
2) In a lexicon there are compound verbs that have these as bases; for example, `looma' and `taaslooma' in WordNet. So the real number of verbs not covered by 1-4 arg smart paradigms can be more than 27.

Inari 17.9.
-----------

Added a field to VP and Clause; found out that the ext field is used for relative clause, so I added a new field `part' for particles. Behaviour hasn't changed.

* Word order: currently produces this

I want to answer to you that I have a cat
mina tahan sinule vastata et minul on kass

I want to answer to you that I have always wanted to see a cat
mina tahan sinule vastata et mina olen tahtnud kassi näha alati

* Complement cases

examples with which to test e.g. here http://eap.ee/public/va_lu/ling-2006-4-2.pdf 

Correct obj case (same as Finnish)
I have seen a baby
mina olen näinud beebi
I haven't seen a baby
mina ei ole näinud beebit

Incorrect (should be nominative in plural also)
I have a good friend
minul on hea sõber
I have good friends
minul on heasid sõbereid

Inari 22.9.
-----------

1) Cases where modifiers don't agree with head: essive, comitative, abessive and terminative. Fixed this in NounEst functions DetCN and AdjCN, and QuestionEst function IdetCN.

Lang> p -cat=NP "two big cats" | l -all
  kaks suurt kassi
  kahe suure kassi
  kahte suurt kassi
  kahte suurde kassi
  kahes suures kassis
  kahest suurest kassist
  kahele suurele kassile
  kahel suurel kassil
  kahelt suurelt kassilt
  kaheks suureks kassiks
  kahe suure kassina (not *kahena suurena kassina)
  kahe suure kassini (etc.)
  kahe suure kassita
  kahe suure kassiga

2) Intending to get rid of all inflected participial forms in verbs.

Added new VForms `PastPartAct' and `PastPartPass' instead of old `PastPart(Act|Pass) AForm'.
Consequently, had to change the following functions:

  ResEst.gf
    oper predV
    ...
        part  : Str = case vi of {
          VIPass => verbs ! PastPartPass (AN (NCase agr.n Nom)) ; 
          _      => verbs ! PastPartAct  (AN (NCase agr.n Nom))
          
Just changed these to PastPartPass and PastPartAct.
There is no number distinction anyway, and it is by default nominative.

  NounEst.gf
  
  Originally
    PPartNP np v2 = {
      s = \\c => np.s ! c ++ v2.s ! PastPartPass (AN (NCase (complNumAgr np.a) Ess)) ;
      a = np.a ;
      isPron = np.isPron
      } ;
      
  After change
    PPartNP np v2 =
      let 
        num : Number     = complNumAgr np.a ;
        part : Str       = v2.s ! PastPartPass ; 
        adj : CommonNoun = nhn (sMaakas part) ; 
        partEssive : Str = adj.s ! (NCase num Ess)
      in {
        s = \\c => np.s ! c ++ partEssive ;
        a = np.a ;
        isPron = np.isPron 
      } ;

So we do the computing of case in this function. Seems better than carry 29 inflected forms per each participle in the verb's inflection table.
Question: is this even a good construction? Sounds weird already in Finnish.
Problem: it doesn't work. 
  Internal error in Compute.ConcreteNew:
    Applying Predef.tk: Expected a value of type String, got VS (VP (VGen 1 []) (LIdent "s")) (VCApp (IC "ResEst",IC "PastPartPass") [])

Another question: I've seen these kinds of constructions, where the adjective formed from a participle doesn't agree with the noun, in any case.

  [Istutatud puudel] tuleb [saastunud õhus] kasvada.
  (...) mida ma [mingitest loetud teostest] arvan (...)
  
Should this be in the grammar? Do the inflected forms appear as modifiers at all? As adverbials yes (e.g. "sinu nimi erinevatesse keeltesse kirjutatuna").

3) Some random testing about object cases, TODO are these correct? 

  three books are eaten    three books aren't eaten
  kolme raamatut süüakse   kolme raamatut ei sööda

  three books have been eaten     three books haven't been eaten
  kolme raamatut ollakse söödud   kolme raamatut ei ole söödud
  
  read a book        don't read a book
  loe raamat         ära loe raamatut
  
  read three books   don't read three books
  loe kolm raamatut  ära loe kolme raamatut


4) Some word order changes in (ResEst) infVP and mkClause, to make "kassi tahtnud näha" -> "kassi näha tahtnud". 
Also changed the place of negation in ResEst.predV: now the grouping is [ei ole] [tahtnud] or [ei taha] [näha]. 
For "ei ole (midagi) näha tahtnud", the verb "näha" is placed into the `compl' field of the VP in previous infVP call. So [ei ole] midagi näha [tahtnud].

Some examples of word orders that mkClause produces.
                   näen
                   ei taha
                   tahan             sind              näha
                   saan              sinust     aru    0
         ma        olen     täna     sinust     aru    saanud                 
declCl = c.subj ++ c.fin ++ c.adv ++ c.compl ++ c.p ++ c.inf ++ c.ext ;

                                  [sind näha]  0      tahtnud  
        täna     olen     ma        sinust     aru    saanud
invCl = c.adv ++ c.fin ++ c.subj ++ c.compl ++ c.p ++ c.inf ++ c.ext 

How about sentences that are inverted this way?

	kui palju   sul    (täna)? aega          on olnud/olnud on?
???Cl = question ++ subj ++ adv ++ compl ++ p ++ fin++inf/inf++fin ++ ext

Lang> p "how many cats do I have" | l
how many cats do I have
kui palju kassi minul on

Is this also acceptable?

5) Changed the name of the part field to p, because the Finnish grammar also has it as p. 
In addition, `part' is already used as an abbreviation for participle and partitive.

_______

6) For the lulz: a quote by John McWhorter from his book Linguistic simplicity and complexity (books.google.se/books?isbn=1934078379).

"Importantly, I have by no means chosen the most baroque comparison possible. Partitive marking in Finnish's close sister Estonian is so much more elaborate in terms of complex interaction with its notoriously complex consonant gradations plus rampant irregularity that its very learnability seems almost questionable."


Inari 25.9.
-----------
1) Created test cases for word order; see tests/wordorder.gfs

2) Added a field to A and AP to show whether it inflects as a modifier.

    A  = {s : Degree => AForm => Str ; infl : Bool} ;
    AP = {s : Bool => NForm => Str   ; infl : Bool} ;     

ParadigmsEst.mkA: if no infl specified, by default mkA builds an inflecting adjective.

    mkA : N -> A = \n -> noun2adjDeg n ** {infl = True} ;
    mkA : N -> Bool -> A = \n,infl -> noun2adjDeg n ** {infl = infl} ;

NounEst.AdjCN checks whether the AP inflects or not, and chooses the right form. 

   AdjCN ap cn = {
      s = \\nf => 
        case ap.infl of {
          False => ap.s ! True ! (NCase Sg Nom) ++ cn.s ! nf ;
          True => case nf of { ...} 
          } 
seotud maja     seotud majad
seotud maja     seotud majade
seotud maja     seotud majasid
seotud majasse  seotud majadesse
seotud majas    seotud majades
seotud majast   seotud majadest
seotud majale   seotud majadele
seotud majal    seotud majadel
seotud majalt   seotud majadelt
seotud majaks   seotud majadeks
seotud majana   seotud majadena
seotud majani   seotud majadeni
seotud majata   seotud majadeta
seotud majaga   seotud majadega


Kaarel 26.09
------------

Went through the Lexicon and tagged two adjectives ('full' and 'ready')
as non-inflecting.

Added oper "N -> Str -> Str -> Bool" which supports the comparison forms.
The implementation of this oper is a bit hackish, due to the fact that
I still don't have complete understanding of lock fields.

Also found two bugs.

1. TODO: fix coordination which still applies the inflection.

Lang> p -cat=NP "valmis kassidena"
OK

Lang> p -cat=NP "valmiste kassidena"
OK: The parser failed at token "kassidena"

Lang> p -cat=NP "valmis ja suurte kassidena"
The parser failed at token "kassidena"
TODO: Should not fail.

Lang> p -cat=NP "valmiste ja suurte kassidena"
TODO: Should fail.

2. TODO: fix: in comparative/superlative the adjective should start inflecting again:

Lang> p -cat=NP "valmimale kassile"
TODO: Should not fail.

p -cat=NP "valmim kassile"
TODO: Should fail.

Inari 1.10.
-----------

If adjectives can have one inflection type in positive and other in comparative, then infl field should be in 
  s => Degree => {s :  whatever ; infl : Bool}. 

Or are non-inflecting adjectives always non-inflecting only in positive, but comparative inflects?
If latter case, then the problem is solved with this:

    UseComparA a = {
      s = \\_,nf => a.s ! Compar ! AN nf ;
      infl = True ; --instead of a.infl
      } ;

Lang> p -cat=NP "valmis kassile"
OK.

Lang> p -cat=NP "valmimale kassile"
OK.

Lang> p -cat=NP "valmim kassile"
OK: The parser failed at token "valmim"


For the other problem, changed ConjAP in ConjunctionEst.
This is what it does:

       {s = \\isMod,nf =>	
          case isMod of { 
            True => case <ap1.infl, ap2.infl> of {
                        <False,False> => ap1.s ! isMod ! (NCase Sg Nom) ++ c 
	                              ++ ap2.s ! isMod ! (NCase Sg Nom) ;   --valmis ja täis kassid
                        <False,True>  => ap1.s ! isMod ! (NCase Sg Nom) ++ c
                                      ++ ap2.s ! isMod ! nf ;               --valmis ja suured kassid
                        <True,False>  => ap1.s ! isMod ! nf ++ c  
	                              ++ ap2.s ! isMod ! (NCase Sg Nom) ;   --suured ja valmis kassid
                         _ => ap1.s ! isMod ! nf ++ c ++ ap2.s ! isMod ! nf --suured ja mustad kassid
                           } ;
		  False => ap1.s ! isMod ! nf ++ c ++ ap2.s ! isMod ! nf --kassid on valmid ja suured
                } ;
 
Lang> p "to ready and big cats" | l
valmis ja suurtele kassidele

Lang> p "to big and ready cats" | l
suurtele ja valmis kassidele

Lang> p "big , bad and ready cats are new , small and full" | l
halvad , valmis ja suured kassid on väiksed , täisid ja uued

_____

Mis doesn't inflect either (http://www.eki.ee/books/ekk09/index.php?p=5&p1=3&id=452
"asesõnad mis (kui ta ei osuta omadusele, vaid on identifitseerivas funktsioonis) ja kogu, nt Mis keelt te räägite? ")

Changed it in QuestionEst IdetCN, now produces

    to which cat do you sing
    mis kassile sina laulad
    
____

So I'm googling random sentences in Estonian if I'm not sure whether the grammar's output is correct or not. I find some interesting stuff. (Also, all our test sentences are about cats.)

"Andsin kassile kitsepiima, nüüd kass juba 2 aastane, ja sööb tubakat nagu vana lehm ja teeb siukseid imelikke liigutusi oma koonuga. muidugi räägib ta, et teda lüpstaks! andke nõu noh!ei tea enam mis kassiga teha :D:D:D:D:D"

Kaarel 02.10.
-------------

Tried parsing with the large lexicon by
creating a PGF from Grammar + DictEst (~40k entries) and applying it to
the Ratsep corpus (~5-word long sentences with single-word verbs).

Extracted most of the ~4000 sentences from the Ratsep/EstCG korpus using
the script tools/extract_ratsep_sentences.sh

Then parsed it like this:

	cat tools/ratsep.txt | tools/Parser +RTS -K100M -RTS Lang1.pgf Lang1Est

where `Parser` comes from the ACE-in-GF project.

Parsing got stuck after 217 sentences at
"direktor käsutas meistri tsehhist oma kabinetti plaani järele"
having filled all my 16GB of memory.

29 sentences (13%) got a parse (the number of parse trees shown after OK):

abilised kiskusid looma põrandale pikali|OK (252)
aednik hoolitses taimede eest|OK (72)
aednik kastis lapi õli sisse|OK (65934)
agentuur levitas kõikjale uudist|OK (9)
ametnik hindas raamatu väärtuse kümnele rublale|OK (972)
ametnik naeratles laua tagant külalistele|OK (216)
ametnikud lömitasid juhataja ees|OK (78)
angerjas roomas korvist põrandale|OK (324)
arhitekt orienteeris kiriku ilmakaarte suhtes|OK (378)
armee sai juhtimise oma kontrolli alla|OK (1342332)
arst katkestas ravikuuri|OK (9)
arst kontrollis koerte kallal preparaati|OK (57690)
arst kontrollis koertel preparaati|OK (3708)
arvamused ühtisid selles küsimuses|OK (38)
astronoom avastas asteroidi|OK (9)
asutused koordineerisid oma tegevuse|OK (78)
asutused liitusid|OK (2)
auto ei saa sellest kohast läbi oja|OK (2376)
auto jäi invaliidile|OK (36)
autor märkis tegelaste kohta paar fakti|OK (1944)
auto sattus miinile|OK (36)
auto sattus miini peale|OK (756)
büroo ja tehas kooskõlastasid töö|OK (27)
büroo pani selles küsimuses vastutuse sekretäri peale|OK (150444)
daam tõmbas kinda käest|OK (54)
detektiiv jätkas otsinguid maja juurest|OK (1080)
direktoril ei lasu selles asjas vastutust|OK (148176)
direktori tütre vahtimine valmistas autojuhtidele rõõmu|OK (2268)
direktor jättis kõik asjad asetäitja otsustada|OK (18)

Many failures are due to missing words e.g. ~25% sentences contain a proper name
which the lexicon does not include.


Parsed also with the robust parser:

	cat tools/ratsep.txt | pgf-parse Lang1.pgf Phr Lang1Est

This works reliably 1sec per sentence (max 3 sec, min 0.2 sec).

	cat parse_results.txt | sed "s/ ms).*//" | sed "s/.*(//" | awk '{if(min==""){min=max=$1}; if($1>max) {max=$1}; if($1<min) {min=$1}; total+=$1; count+=1} END {print total/count, max, min}'
	1004.41 3060 200

Did not parse all the sentences though.
Results: 52/415 (13%)
Success means that a tree was found (but only the first tree was generated).
No trees contained ?-nodes.

Other things to try (with this corpus):

  - eliminate lexicon problems
    - support compounds nouns
    - support adjectives (not so many in the corpus though)
    - allow the parser to skip over unknown words (e.g. proper names)
  - map trees to English trees, e.g. simply by ???_N -> man_N, ???_V2 -> hit_V2, and linearize them with LangEng or ParseEng

Kaarel 05.10.
-------------

Added some adjectives and some MWVs to DictEst. It now contains 53088 entries with this
frequency distribution of constructor patterns:

  32157 mkN
  10197 mkV (mkV )
   3496 mkAdv
   3402 mkV
   3006 mkA (mkN )
    492 mkV2 (mkV )
    320 mkV2 (mkV ) cpartitive
     18 mkVV (mkV )

where "mkV (mkV )" stands for MWVs.

Inari 06.10
-----------
Made test-(noun|verb)-coverage.sh to output a new file, (nouns|verbs).incorrect.txt.

Added new script, test-(noun|verb)-frequency.sh, which looks up the words in http://www.cl.ut.ee/ressursid/sagedused/tabel1.txt and outputs the word and its frequency.

(Note that tabel1 is ISO-8859-1 and uses sh and zh for š and ž; I modified the (nouns|verbs).incorrect.txt files manually before I ran the script. 
"Modified manually" = open in emacs; C-x RET f <encoding>; then search and replace the funny chars).

cut -f1 verbs.incorrect.frequencies.txt | tr '[0-9]' 'x' | sort | uniq -c
    311
     45 x
    150 xx
     49 xxx
     11 xxxx
      1 xxxxx
    
Same for nouns: 
   1613
    191 x
    544 xx
    183 xxx
     19 xxxx

Kaarel 07.10
------------

Added a script that does the
full outer join of frequency data and smart paradigm coverage evaluation output.
This gives a more general output that can be used for all kinds of analysis.
(TODO: Does not work correctly yet with non-ascii letters, don't know why...)

Example 1. Frequent words that are not correctly analyzed:

	./join-freq-diff.bash | grep '[0-9]$' | sort -nr -k3 | head -10

miski	P	2276	5-6
inimene	S	2268	6
naine	S	1666	6
asi	S	1256	2-3-4-5-6
hea	A/S	1025	6
noor	A/S	589	2-3-4-5-6
rahvas	S	542	2-4-6
nimi	S	522	2-3-4-5-6
laud	S	438	2-3-4-5-6
otsus	S	411	6

Example 2. (Same as Inari's cut -f1 verbs.incorrect.frequencies.txt | tr '[0-9]' 'x' | sort | uniq -c)

	./join-freq-diff.bash | grep '[0-9]$' | cut -f3 | tr '[0-9]' 'x' | sort | uniq -c

   1678 #
     96 x
    231 xx
     39 xxx
      5 xxxx


Kaarel 07.10
------------

Fixed the join. Some tests to verify that it works correctly.

Nouns with 3-arg oper.

  20843
    264 5-6
    253 2-3-4-5-6
    120 6
     63 2-4-6
     61 2-4-5-6
     44 3-5-6
     36 3
     36 2-4
     31 3-4-5-6
     13 2-3-4-5
      8 2
      3 2-3-4
      1 5
Coverage: 20843 out of 21776 = .9571

Number of errors = 21776-20843 = 933

Number of errors with join:

	./join-freq-diff.bash | grep '[0-9]$' | wc -l
	933

Top 20 most frequent words that are incorrectly analyzed.

	./join-freq-diff.bash | grep '[0-9]$' | sort -nr -k3 | head -20
mees	S	2406	2-3-4-5-6
miski	P	2276	5-6
inimene	S	2268	6
naine	S	1666	6
käsi	S	1408	2-3-4-5-6
laps	S	1281	2-3-4-5-6
iga	P/S	1276	2-4
asi	S	1256	2-3-4-5-6
pea	D/S	1253	6
hea	A/S	1025	6
nägu	S	685	2-4
keel	S	643	2-3-4-5-6
uks	S	613	2-3-4-5-6
noor	A/S	589	2-3-4-5-6
hääl	S	575	2-3-4-5-6
vesi	S	562	2-3-4-5-6
nimi	S	522	2-3-4-5-6
meel	S	500	2-3-4-5-6
õhtu	S	476	5-6
tuba	S	438	2-4

Out of the total of 933 errors, 580 (62%) are not among the 10k most frequent words.

	./join-freq-diff.bash | grep '[0-9]$' | cut -f3 | tr '[0-9]' 'x' | sort | uniq -c | sort -nr
    580 #
    193 xx
     82 xxx
     68 x
     10 xxxx

Distribution of errors that are not frequent words by word length.

	./join-freq-diff.bash | grep '[0-9]$' | cut -f1,3 | grep '#' | cut -f1 | tr '[a-zõäöüšž]' 'x' | sort | uniq -c | sort -nr
    165 xxxxxx
    118 xxxxxxx
    102 xxxxx
     84 xxxx
     58 xxxxxxxx
     19 xxxxxxxxx
     14 xxx
     10 xxxxxxxxxx
      2 xxxxxxxxxxxx
      2 xxxxxxxxxxx
      2 xxxx|xxxx
      1 xxxxxxx|xxxxxxxx
      1 xxxxxxxxxxxxx
      1 xxxxx|xxxxxx
      1 xxx|xxxxx

i.e. the largest group are 6-letter words.

There are lots that end with 'ja'.

	./join-freq-diff.bash | grep '[0-9]$' | cut -f1,3 | grep '#' | cut -f1 | grep 'ja$' | wc -l
	84

All of them (with one exception: gerilja) are -ja derivations.
(TODO: put them into AASTA, i.e. kündja -> kündjaid, not kündja -> kündjasid)


Inari 07.10.
------------
Starting point: 3-arg:  20847 out of 21776 = .9573

Added -ja and -la => aasta in 1-arg smart paradigm.
Added bunch of tõuge indicators in 2-arg, don't cover all but don't cause errors in other classes either.
Added 4-arg smart paradigm: distinguishes between joonis and segadus, and catches reliably all tõuge type words.

Latest coverages for 1-4 arg paradigms:

1-arg: # 19845    % .9113

2-arg: # 20004    % .9186

3-arg: # 21045    % .9664

4-arg: # 21261    % .9763

Common patterns in nouns unrecognized by 3-arg oper (numbers changed sligtly as I made changes to smart paradigms; not a radical difference anyway):

2-3-4-5-6 
  * 77 ending in r/l; around half type pipar, küünal
     (non-productive, http://www.eki.ee/dict/qs/index.cgi?Q=37&F=I finds only 32 words)
     
  * 69 ending in i; there are many mägi:mäe, ori:orja; old, non-productive words
  (heuristic: if I know the word from Finnish, it doesn't make sense to form elaborate rules to handle it and its kind.)
  

  
6 
  * 115 ending in s, confusion between joonis:jooniseid and segadus:segadusi. This is fixed with 4-arg paradigm.

3-5-6
5-6 
  * Very heterogenous. I'm learning funny words ("tohuvabohu").

2-4-6 (55)
2-4-5-6 (59) 
  * 111 of 114 are 2-syllable and end in e.
    Added following in 4-arg constructor.
      <_ +"e", _+"e", _+"et", _+"sid"> => hjk_type_III_ratsu paat ; 
      <_ +"e", _+"e", _+"et", _+"eid"> => hjk_type_VII_touge2 paat paadi ;
    Added 2-arg version of hjk_type_VII_touge, because with 1-arg version got still 67 errors due to consonant gradation.
    

Notes:

2-arg doesn't do much. We get for sure reegel:reegli and paber:paberi, and some of tõuge type words.
Words like meri:mere and ori:orja could be possible to distinguish (very characteristical nom+gen combination), but they are small and unproductive classes.
Some bigger classes are indistinguishable in nom and gen, such as
imelik:imeliku vs. voolik:vooliku ; maakas:maaka vs. hammas:hamba. 

Biggest number of unrecognized words, with all constructors, in 2-3-4-5-6.

In various classes:
* words like "mänedžer", "multiplex" ; maybe better foreign detection in 1-arg?
* words like "nimega", "käivitumisel"; also many words that end in "ks" and some of them seem translatives of common words (searched from http://www.eki.ee/dict/qs/ and didn't find nom with ks, e.g. "eluks" just directs to "elu".) Not very large group of the test data though. 

cat *incorrect.txt | grep "ks$" | sort | uniq | wc
     76      76     578
cat *incorrect.txt | grep "ga$" | sort | uniq | wc
     28      28     231

Inari 08.10
-----------


Experiment: made 4-arg paradigm insert all used specified forms (1, 2, 3, 6) to the 6 forms. This leads to following coverage:

21310
 256 4-5
 166 5
  44 4
Coverage: 21310 out of    21776 = .9786

As opposed to
21261
 212 2-3-4-5-6
 103 5-6
  48 3-5-6
  36 3
  36 2-4
  31 3-4-5-6
  15 3-5
  13 2-3-4-5
   8 2
   5 6
   5 2-4-6
   3 2-3-4
Coverage: 21261 out of    21776 = .9763

Note that the full forms contain more errors, because plural genitive is used as a base for other plural forms, and it is wrong still in the 2.14 % of errors.

Actually might make sense to do this to 2-arg (sg nom + sg gen) oper as well, because sg gen is used as base for all other sg forms except nom, part and ill.

Inari 08.10
-----------

Experiment 2: what if nForms4 gets Pl Gen instead of Pl Part.
Result: Identical to 3-arg.
So apparently tõuge type words get recognized already at previous stages.
The increase of ~300 words that comes from 4-arg Pl Part is from joonis/segadus words.


Ran tests again with updated data + using the smart paradigms where
user-specified forms are added

1-arg
Before changing place of rule ja/ia/la:
Coverage: 19814 out of    21734 = .9116
After:
Coverage: 19748 out of    21734 = .9086

2-arg
Before:
Coverage: 19992 out of    21734 = .9198
After:
Coverage: 19926 out of    21734 = .9168

3-arg
Before:
Coverage: 21056 out of    21734 = .9688
After:
Coverage: 20990 out of    21734 = .9657

4-arg
(both After:)
using pl gen
Coverage: 20990 out of    21734 = .9657

using pl part
Coverage: 21208 out of    21734 = .9757


Kaarel 09.10
------------

Refactored the script that tests mkN.

Nouns.
./test-mkN.bash ../data/nouns.6forms.csv

1-arg pattern: (@F[0])
  19748
    797 2-3-4-5-6
    357 2-3-4-5
    164 3-5-6
    148 5-6
    136 2-4-6
    118 6
     88 2-4-5-6
     79 3-4-5-6
     36 2-4
     35 3
     19 2
      5 3-5
      3 2-3-4
      1 5
Coverage: 19748 out of 21734 = .9086
2-arg pattern: (@F[0..1])
  19926
    792 3-4-5-6
    357 3-4-5
    179 3-5-6
    150 5-6
    118 6
     98 4-6
     36 4
     35 4-5-6
     35 3
      5 3-5
      3 3-4
Coverage: 19926 out of 21734 = .9168
3-arg pattern: (@F[0..2])
  20990
    309 4-5-6
    240 5-6
    121 6
     39 4
     22 4-6
     13 4-5
Coverage: 20990 out of 21734 = .9657
4-arg pattern: (@F[0..2], @F[5])
  21208
    254 4-5
    228 5
     44 4
Coverage: 21208 out of 21734 = .9757


Adjectives don't benefit from the extra arguments.
./test-mkN.bash ../data/adj.6forms.csv

1-arg pattern: (@F[0])
   3023
    211 2-3-4-5-6
     64 6
     34 2-4-6
     18 5-6
     15 2-4-5-6
      8 2-3-4-5
      3 3-5-6
      3 3-5
      2 3-4-5-6
      1 2
Coverage: 3023 out of 3382 = .8938
2-arg pattern: (@F[0..1])
   3024
    213 3-4-5-6
     64 6
     34 4-6
     18 5-6
     15 4-5-6
      8 3-4-5
      3 3-5-6
      3 3-5
Coverage: 3024 out of 3382 = .8941
3-arg pattern: (@F[0..2])
   2935
    349 4-5-6
     64 6
     19 5-6
     14 4-6
      1 5
Coverage: 2935 out of 3382 = .8678
4-arg pattern: (@F[0..2], @F[5])
   2552
    481 5
    345 4-5
      4 4
Coverage: 2552 out of 3382 = .7545




Fixed mk3N and mk4N to not handle -nud/-tud and some forms of -ne.

Adjectives:

3-arg pattern: (@F[0..2])
   3141
    143 4-5-6
     64 6
     19 5-6
     14 4-6
      1 5
Coverage: 3141 out of 3382 = .9287

4-arg pattern: (@F[0..2], @F[5])
   3219
    139 4-5
     20 5
      4 4
Coverage: 3219 out of 3382 = .9518


Nouns:

4-arg pattern: (@F[0..2], @F[5])
  21217
    254 4-5
    219 5
     44 4
Coverage: 21217 out of 21734 = .9762


Kaarel 10.10
------------

Refactored the smart paradigms testing scripts.
Compared the errors with frequent words.

$ cat mkV4.diff.txt | ./join-freq-diff.bash | grep '[0-9]$'
jooma	V	221	5-6-7-8
jääma	V	2421	6
kaitsma	V	202	6
käima	V	1250	5-7-8
looma	V	262	5-6-7-8
lööma	V	533	5-6-7-8
maitsma	V	39	6
minema	V	3115	3-6-7
müüma	V	305	5-7-8
olema	V	44904	3
pooma	V	17	5-7-8
saama	V	5894	6
sööma	V	298	5-6-7-8
taaslooma	#	#	5-6-7-8
tooma	V	834	5-6-7-8
viima	V	802	5-7-8

$ cat prev/mkN1.diff.txt | ./freq_err.bash
1188 rare words among 1986 errors = .5981

$ cat prev/mkV1.diff.txt | ./freq_err.bash
311 rare words among 567 errors = .5485


Also, improved the handling of -ia words.

input: ../data/nouns.6forms.csv
mkN 1-arg pattern: (@F[0])
  19797
    797 2-3-4-5-6
    357 2-3-4-5
    148 5-6
    136 2-4-6
    118 6
    115 3-5-6
     88 2-4-5-6
     79 3-4-5-6
     36 2-4
     35 3
     19 2
      5 3-5
      3 2-3-4
      1 5
coverage: 19797 out of 21734 = .9108


Kaarel 22.10
------------

Did some cleanup and generalization of the 2-arg noun oper.
Highlights: 2-arg on nouns improved 4%, and on adjectves 3%.
For some reason lost 0.5% on 3- and 0.2% on 4-arg opers, TODO: investigate.

NOUNS
input: ../data/nouns.6forms.csv
mkN 1-arg pattern: (@F[0])
  19798 
    797 2-3-4-5-6
    357 2-3-4-5
    148 5-6
    136 2-4-6
    117 6
    115 3-5-6
     88 2-4-5-6
     79 3-4-5-6
     36 2-4
     35 3
     19 2
      5 3-5
      3 2-3-4
      1 5
coverage: 19798 out of 21734 = .9109
mkN 2-arg pattern: (@F[0..1])
  20670 
    360 3-4-5-6
    183 6
    150 5-6
    140 3-5-6
    101 4-6
     36 4
     35 4-5-6
     35 3
     16 3-4-5
      5 3-5
      3 3-4
coverage: 20670 out of 21734 = .9510
mkN 3-arg pattern: (@F[0..2])
  20947 
    267 4-5-6
    256 5-6
    186 6
     39 4
     25 4-6
     14 4-5
coverage: 20947 out of 21734 = .9637
mkN 4-arg pattern: (@F[0..2], @F[5])
  21242 
    232 5
    216 4-5
     44 4
coverage: 21242 out of 21734 = .9773


ADJECTIVES
input: ../data/adj.6forms.csv
mkN 1-arg pattern: (@F[0])
   3045 
    211 2-3-4-5-6
     42 6
     34 2-4-6
     18 5-6
     15 2-4-5-6
      8 2-3-4-5
      3 3-5-6
      3 3-5
      2 3-4-5-6
      1 2
coverage: 3045 out of 3382 = .9003
mkN 2-arg pattern: (@F[0..1])
   3166 
    101 3-4-5-6
     42 6
     34 4-6
     18 5-6
     15 4-5-6
      3 3-5-6
      3 3-5
coverage: 3166 out of 3382 = .9361
mkN 3-arg pattern: (@F[0..2])
   3221 
     85 4-5-6
     42 6
     19 5-6
     14 4-6
      1 5
coverage: 3221 out of 3382 = .9523
mkN 4-arg pattern: (@F[0..2], @F[5])
   3277 
     81 4-5
     20 5
      4 4
coverage: 3277 out of 3382 = .9689


Kaarel 22.10
------------

Nouns improved a bit:

mkN 2-arg pattern: (@F[0..1])
  20738 
    322 3-4-5-6
    150 5-6
    141 3-5-6
    117 6
    101 4-6
     51 3-4-5
     36 4
     35 4-5-6
     35 3
      5 3-5
      3 3-4
coverage: 20738 out of 21734 = .9541
mkN 3-arg pattern: (@F[0..2])
  21024 
    246 5-6
    235 4-5-6
    120 6
     42 4-5
     42 4
     25 4-6
coverage: 21024 out of 21734 = .9673
mkN 4-arg pattern: (@F[0..2], @F[5])
  21253 
    222 5
    212 4-5
     47 4
coverage: 21253 out of 21734 = .9778


2014-01-14 (Kaarel)
-------------------

Improved and added compound nouns in DictEst. Previously they were generated by the
1-arg oper. Now the 6-arg oper is applied to their last part.

Also, WordNet nouns longer than 10 characters are now included.
Now 61008 nouns are included and only 427 excluded because they contain digits
and/or capital letters. As a result DictEst grew by ~30k entries.

The entries were generated by the following method.

	# Extract nouns from WordNet
	cat kb67a-utf8.tix | estwn-to-etsyn.bash n | sed "s/ \/\/.*//" > nouns.txt

	# Use Morfessor to generate a noun segmentation model based on these nouns
	# and then use this model to segment the nouns.
	# Note that the model generation seems to be a non-deterministic process,
	# i.e. you get a different model at every run. TODO: verify this
	bash split-words.bash nouns.txt

	# Generate lexicon entries (part of make-dict.sh) taking the forms
	# from nouns.6forms.csv. If the input segmenation is "a b c" then look
	# for forms for "abc", "bc" and "c" in that order, preferring the longest one.
	# If no suffix matches then generate a 1-arg oper for "abc", if "bc" matches
	# then generate (mkN "a" (mkN bc-forms)).
	cat nouns.seg | nouns-to-gf.py --forms nouns.6forms.csv

Notes:
  - nouns-to-gf.py was generalized, i.e. it can still be used on files
    where the words have not been segmented
  - the compound splitting looks quite OK, but we haven't done any formal evaluation,
    e.g. against Filosoft's compound splitter.
    Some mistakes in splitting would be also invisible to the end-user because
    wrong forms would not necessarily be generated (see: 'kokk+aja')
  - the forms of the compound are not always determined by the last part, e.g.
    'palk' is ambiguous between palk/palgi and palk/palga, and it's kind of
    OK to represent just one of them in the lexicon; however a compound 'aastapalk'
    or 'kantpalk' chooses just one of the two paradigms, potentially resulting in
    incorrect forms in the lexicon: kantpalk/*kantpalga.
    TODO: we should improve the representation of nouns.6forms.csv so that we could
    generate a lexicon entry for every paradigm. In case of compound words it would
    result in overgeneration, but the correct forms would then be also generated which
    is OK for parsing applications.

2014-03-19 (Kaarel)
-------------------

Frequency distribution of HJK noun classes based on the current implementation.

::

	cat data/nouns.6forms.csv | sed "s/,.*//" | python tools/cc.py -r estonian/HjkClassify.gf --oper hjk_type | gf --run | sort | uniq -c | sort -nr
   7908 Vb_oluline
   5035 IVa_aasta
   4537 VI_link2_i
   1080 IVb_audit_i
    515 III_ratsu
    469 IVb_audit_u
    447 II_ema
    296 IVb_audit1
    241 VI_imelik
    229 Va_otsene
    215 I_koi
    209 VII_tõuge
    159 IVb_maakas
    144 IVb_audit_a
    127 VI_seminar
    123 VI_meeskond

Only main types::

   7908 Vb
   5035 IVa
   5028 VI
   2148 IVb
    515 III
    447 II
    229 Va
    215 I
    209 VII

   7908 Vb_oluline
   5035 IVa_aasta
   4537 VI_link
   1989 IVb_audit
    515 III_ratsu
    447 II_ema
    241 VI_imelik
    229 Va_otsene
    215 I_koi
    209 VII_tõuge
    159 IVb_maakas
    127 VI_seminar
    123 VI_meeskond

2014-06-22 (Kaarel)
-------------------

Generate DictEst.gf based on Vabamorf noun splits

3k (out of 61k) nouns changed compared to Morfessor's splits.
Typically the change was for the better, thus checked it in.
